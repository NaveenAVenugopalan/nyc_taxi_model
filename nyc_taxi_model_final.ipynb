{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4850df3-e95a-40f0-b3c4-fc295a182c10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Download yellow taxi data \n",
    "def download_and_load_yellow_tripdata(year, month):\n",
    " \n",
    "   import os\n",
    "   import requests\n",
    "   from pyspark.sql import SparkSession\n",
    "   \n",
    "   \n",
    "   # Format month with leading zero if needed\n",
    "   month_str = str(month).zfill(2)\n",
    "   file_name = f\"yellow_tripdata_{year}-{month_str}.parquet\"\n",
    "   url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{file_name}\"\n",
    "   \n",
    "   # Define paths\n",
    "   local_path = f\"/tmp/{file_name}\"\n",
    "   dbfs_path = f\"/FileStore/tables/{file_name}\"\n",
    "   \n",
    "   # Download file if it doesn't exist locally . Download to local path as copy to dbfs was not working\n",
    "   if os.path.exists(local_path):\n",
    "       print(f\"File {local_path} already exists. Skipping download.\")\n",
    "   else:\n",
    "       print(f\"Downloading {file_name}...\")\n",
    "       try:\n",
    "           response = requests.get(url)\n",
    "           if response.status_code == 200:\n",
    "               with open(local_path, \"wb\") as f:\n",
    "                   f.write(response.content)\n",
    "               print(f\"Download complete to {local_path}\")\n",
    "           else:\n",
    "               print(f\"Error: Unexpected status code {response.status_code}\")\n",
    "               return None\n",
    "       except requests.exceptions.RequestException as e:\n",
    "           print(f\"An error occurred: {e}\")\n",
    "           return None\n",
    "   \n",
    "   # Copy file to DBFS\n",
    "   dbutils.fs.cp(f\"file:{local_path}\", f\"dbfs:{dbfs_path}\")\n",
    "   print(f\"File copied to DBFS at {dbfs_path}\")\n",
    "   \n",
    "   # Verify file exists in DBFS\n",
    "   files = dbutils.fs.ls(f\"/FileStore/tables/\")\n",
    "   file_exists = any(f.name == file_name for f in files)\n",
    "   print(f\"File verification in DBFS: {'Success' if file_exists else 'Failed'}\")\n",
    "   \n",
    "   # Load the data from DBFS\n",
    "   if file_exists:\n",
    "       raw_df = spark.read.parquet(f\"/FileStore/tables/{file_name}\")\n",
    "       print(f\"Data loaded successfully. Row count: {raw_df.count()}\")\n",
    "       raw_df.printSchema()\n",
    "       raw_df.show(5)\n",
    "   else:\n",
    "       print(\"ERROR: File not found in DBFS, cannot load data\")\n",
    "       return None\n",
    "   \n",
    "   print(f\"Number of rows loaded to raw_df is: {raw_df.count()}\")\n",
    "   return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce5089df-b886-4ed4-9193-3307b98e5d86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check and remove duplicate rows \n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "def process_duplicates(raw_df):\n",
    "    \n",
    "  \n",
    "    # Count original records\n",
    "    original_count = raw_df.count()\n",
    "    print(f\"Original record count before deduplication: {original_count}\")\n",
    "    \n",
    "    # Count distinct records\n",
    "    distinct_df = raw_df.dropDuplicates()\n",
    "    distinct_count = distinct_df.count()\n",
    "    print(f\"Distinct record count after dedupliation: {distinct_count}\")\n",
    "    \n",
    "    # Calculate duplicate count\n",
    "    duplicate_count = original_count - distinct_count\n",
    "    \n",
    "      \n",
    "    # Check if duplicates exist and handle accordingly\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"Duplicates found: {duplicate_count}\")\n",
    "        \n",
    "        # Store duplicates in a separate dataframe\n",
    "        window_spec = Window.partitionBy(*raw_df.columns)\n",
    "        raw_df_with_count = raw_df.withColumn(\"occurrence_count\", count().over(window_spec))\n",
    "        raw_df_duplicates = raw_df_with_count.filter(\"occurrence_count > 1\").drop(\"occurrence_count\")\n",
    "        \n",
    "        # Use the distinct dataframe (duplicates removed)\n",
    "        raw_dedup_df = distinct_df\n",
    "        \n",
    "        print(f\"QUALITY REPORT: Number of duplicates removed: {duplicate_count}\")\n",
    "    else:\n",
    "        print(\"No duplicates found\")\n",
    "        \n",
    "        # No duplicate Keep original dataframe as is\n",
    "        raw_dedup_df = raw_df\n",
    "        raw_df_duplicates = None\n",
    "                      \n",
    "        print(\"QUALITY REPORT: No duplicates found\")\n",
    "    \n",
    "    return raw_dedup_df, raw_df_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7c5beda-73f9-4a73-886b-82490713aab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows with NULL on selected columns \n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def drop_null_rows(df):\n",
    "    \n",
    "    columns_to_check =  [\"trip_distance\",\"total_amount\"]\n",
    "    # Store the original row count\n",
    "    original_count = df.count()\n",
    "    \n",
    "    # Create a dictionary to track how many nulls were found in each column\n",
    "    null_counts = {}\n",
    "    \n",
    "    # Get counts of nulls for each column\n",
    "    for column in columns_to_check:\n",
    "        null_count = df.filter(col(column).isNull()).count()\n",
    "        null_counts[column] = null_count\n",
    "    \n",
    "    # Drop rows with nulls in any of the specified columns\n",
    "    clean_no_null_df = df\n",
    "    for column in columns_to_check:\n",
    "        clean_no_null_df = clean_no_null_df.filter(col(column).isNotNull())\n",
    "    \n",
    "    # Calculate the total rows removed\n",
    "    final_count = clean_no_null_df.count()\n",
    "    rows_removed = original_count - final_count\n",
    "    \n",
    "    print(f\"Original row count: {original_count}\")\n",
    "    print(f\"Final row count: {final_count}\")\n",
    "    print(f\"Total rows removed: {rows_removed}\")\n",
    "    print(\"Null counts by column:\")\n",
    "    \n",
    "    for column, count in null_counts.items():\n",
    "        print(f\"  - {column}: {count} rows\")\n",
    "    \n",
    "    return clean_no_null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "519a738b-1fe8-486d-a4b2-86fc5a062cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def convert_negative_to_positive_amounts(df):\n",
    "    \"\"\"\n",
    "    Convert negative amounts to positive values for specified currency columns.\n",
    "   \n",
    "    \"\"\"\n",
    "   \n",
    "    from pyspark.sql import functions as F\n",
    "    \n",
    "    # Hardcoded list of currency columns to fix\n",
    "    columns_to_fix = [\n",
    "        \"fare_amount\",\n",
    "        \"tip_amount\",\n",
    "        \"tolls_amount\",\n",
    "        \"extra\",\n",
    "        \"mta_tax\",\n",
    "        \"improvement_surcharge\",\n",
    "        \"congestion_surcharge\",\n",
    "        \"Airport_fee\",\n",
    "        \"total_amount\"\n",
    "    ]\n",
    "   \n",
    "    # Original row count for reporting\n",
    "    original_count = df.count()\n",
    "   \n",
    "    # Count negative values before conversion\n",
    "    negative_counts = {}\n",
    "    for col_name in columns_to_fix:\n",
    "        try:\n",
    "            neg_count = df.filter(F.col(col_name) < 0).count()\n",
    "            negative_counts[col_name] = neg_count\n",
    "        except:\n",
    "            # Handle column not found\n",
    "            negative_counts[col_name] = \"Column not found\"\n",
    "   \n",
    "    # Use Absolute value to convert negative to positive\n",
    "    df_positive = df.select(\n",
    "        *[F.abs(F.col(c)).alias(c) if c in columns_to_fix else F.col(c) for c in df.columns]\n",
    "    )\n",
    "   \n",
    "    # Print summary information\n",
    "    print(\"Negative currency values found (before conversion):\")\n",
    "    for col, count in negative_counts.items():\n",
    "        print(f\"  - {col}: {count}\")\n",
    "   \n",
    "    print(f\"\\nTotal rows processed: {original_count}\")\n",
    "    print(f\"All specified currency amounts converted to positive values.\")\n",
    "   \n",
    "    return df_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62a945e9-2fcb-4729-bac5-5105edac892c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# drop unwanted columns if needed , code not written as of now \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8c0e36a-7946-4866-8581-c57b2f16d385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enrich data with some derived columns \n",
    "\n",
    "from pyspark.sql.functions import hour, to_date, date_format, when, col, round, unix_timestamp\n",
    "\n",
    "def enhance_taxi_data(df):\n",
    "   \n",
    "   # Track the original row count\n",
    "   original_count = df.count()\n",
    "   \n",
    "   # Apply all enhancements as a chain\n",
    "   enhanced_df = (df\n",
    "       # Pickup hour extracted from the tpep_pickup_datetime\n",
    "       .withColumn(\n",
    "           \"pickup_hour\",\n",
    "           hour(\"tpep_pickup_datetime\")\n",
    "       )\n",
    "       # Pickup date extracted from the tpep_pickup_datetime\n",
    "       .withColumn(  \n",
    "           \"pickup_date\",\n",
    "           to_date(\"tpep_pickup_datetime\")\n",
    "       )\n",
    "       # Pickup day of week extracted from the tpep_pickup_datetime\n",
    "       .withColumn(  \n",
    "           \"pickup_day_of_week\",\n",
    "           date_format(\"tpep_pickup_datetime\", \"EEEE\")\n",
    "       )\n",
    "       # Price per mile extracted from the trip_distance and fare_amount when not zero\n",
    "       .withColumn(  \n",
    "           \"price_per_mile\",\n",
    "           when(col(\"trip_distance\") > 0, round(col(\"fare_amount\") / col(\"trip_distance\"), 2)).otherwise(0)\n",
    "       )\n",
    "       # Trip duration in minutes calculated from pickup and dropoff timestamps\n",
    "       .withColumn(\n",
    "           \"trip_duration_minutes\",\n",
    "           round((unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60, 2)\n",
    "       )\n",
    "   )\n",
    "   \n",
    "   # Verify row count remains unchanged\n",
    "   final_count = enhanced_df.count()\n",
    "   \n",
    "   # Display summary information\n",
    "   print(f\"Data enhancement complete:\")\n",
    "   print(f\"- Original columns: {len(df.columns)}\")\n",
    "   print(f\"- Enhanced columns: {len(enhanced_df.columns)}\")\n",
    "   print(f\"- New columns added: {len(enhanced_df.columns) - len(df.columns)}\")\n",
    "   print(f\"- Row count: {final_count} (unchanged from original: {original_count})\")\n",
    "   \n",
    "   return enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27d554f4-cba2-401f-b41d-866c7fa228d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# : Create dimensional model that can be generated from original data set \n",
    "\n",
    "def create_dimensional_model(df):\n",
    "    \"\"\"\n",
    "    Create a dimensional model from the cleaned data\n",
    "    \"\"\"\n",
    "    print(\"Creating dimensional model...\")\n",
    "    from pyspark.sql import functions as sf\n",
    "    # Dimension: Time\n",
    "    dim_time = df.select(\n",
    "        \"tpep_pickup_datetime\",\n",
    "        \"pickup_hour\",\n",
    "        \"pickup_date\",\n",
    "        \"pickup_day_of_week\"\n",
    "    ).distinct()\n",
    "    \n",
    "    \n",
    "    # Nor creating a location dimension as https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv already has location_id and related details \n",
    "\n",
    "        \n",
    "    # Fact Table: Trips\n",
    "    fact_trips = df.select(\n",
    "        sf.monotonically_increasing_id().alias(\"trip_id\"),\n",
    "        \"VendorID\",\n",
    "        \"tpep_pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"passenger_count\",\n",
    "        \"payment_type\",\n",
    "        \"RateCodeID\",\n",
    "        \"trip_distance\",\n",
    "        \"fare_amount\",\n",
    "        \"tip_amount\",\n",
    "        \"total_amount\",\n",
    "        \"trip_duration_minutes\",\n",
    "        \"price_per_mile\"\n",
    "    )\n",
    "    \n",
    "    # Display table counts\n",
    "    print(f\"Time dimension count: {dim_time.count()}\")\n",
    "    print(f\"Fact table count: {fact_trips.count()}\")\n",
    "    dim_time.printSchema()\n",
    "    fact_trips.printSchema()\n",
    "    return {\n",
    "        \"dim_time\": dim_time,\n",
    "        \"fact_trips\": fact_trips\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec6e9b04-db64-4774-ab55-83494cbaab0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save tables to Delta format in Databricks\n",
    "def save_to_delta(tables_dict, base_path=\"/FileStore/tables/nyc_taxi\"):\n",
    "    \"\"\"\n",
    "    Save the dimensional model tables to Delta format\n",
    "    \"\"\"\n",
    "    print(f\"Saving tables to Delta format at {base_path}...\")\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS nyc_db\")\n",
    "    print(f\"Database nyc_db created or already exists\")\n",
    "    \n",
    "    for table_name, df in tables_dict.items():\n",
    "        table_path = f\"{base_path}/{table_name}\"\n",
    "        print(f\"Saving table {table_name} to {table_path}\")\n",
    "        df.printSchema()\n",
    "        # Save as Delta table with Schema change adaption\n",
    "        df.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").save(table_path)\n",
    "        print(f\"Saved {table_name} to Delta format\")\n",
    "\n",
    "        # Create temp view for SQL queries\n",
    "        df.createOrReplaceTempView(table_name)\n",
    "        # Register the table in the metastore\n",
    "        spark.sql(f\"CREATE TABLE IF NOT EXISTS nyc_db.{table_name} USING DELTA LOCATION '{table_path}'\")\n",
    "        print(f\"Table nyc_db.{table_name} registered in metastore\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    print(\"All tables saved to Delta format successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7de025ef-5a51-44b0-bdfe-0903ffdf9351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create additional dimension not from main raw data \n",
    "\n",
    "def create_payment_type_dimension():\n",
    "    \n",
    "    from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "    \n",
    "    # Create a DataFrame with payment type mappings\n",
    "    payment_types_data = [\n",
    "        (1, \"Credit card\"),\n",
    "        (2, \"Cash\"),\n",
    "        (3, \"No charge\"),\n",
    "        (4, \"Dispute\"),\n",
    "        (5, \"Unknown\"),\n",
    "        (6, \"Voided trip\")\n",
    "    ]\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"payment_type\", IntegerType(), False),\n",
    "        StructField(\"payment_type_desc\", StringType(), False)\n",
    "    ])\n",
    "    dim_payment_type = spark.createDataFrame(payment_types_data, schema)\n",
    "    delta_location = \"dbfs:/FileStore/tables/dim_payment_type\"\n",
    "    dim_payment_type.write.format(\"delta\").mode(\"overwrite\").save(delta_location)\n",
    "\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS nyc_db.dim_payment_type USING DELTA LOCATION '{delta_location}'\")\n",
    "    print(f\"Table nyc_db.dim_payment_type registered in metastore\")\n",
    "    print(\"Sample data:\")\n",
    "    dim_payment_type.show(5)\n",
    "    \n",
    "    \n",
    "    return dim_payment_type\n",
    "    \n",
    "    \n",
    "def create_rate_code_dimension():\n",
    "    \n",
    "    from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "    \n",
    "    # Create a DataFrame with rate code mappings\n",
    "    rate_codes_data = [\n",
    "        (1, \"Standard rate\"),\n",
    "        (2, \"JFK\"),\n",
    "        (3, \"Newark\"),\n",
    "        (4, \"Nassau or Westchester\"),\n",
    "        (5, \"Negotiated fare\"),\n",
    "        (6, \"Group ride\"),\n",
    "        (99, \"Unknown\")\n",
    "    ]\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"RateCodeID\", IntegerType(), False),\n",
    "        StructField(\"rate_code_desc\", StringType(), False)\n",
    "    ])\n",
    "    \n",
    "    dim_rate_code=spark.createDataFrame(rate_codes_data, schema)\n",
    "    delta_location = \"dbfs:/FileStore/tables/dim_rate_code\"\n",
    "    dim_rate_code.write.format(\"delta\").mode(\"overwrite\").save(delta_location)\n",
    "\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS nyc_db.dim_rate_code USING DELTA LOCATION '{delta_location}'\")\n",
    "    print(f\"Table nyc_db.dim_rate_code registered in metastore\")\n",
    "    print(\"Sample data:\")\n",
    "    dim_rate_code.show(5)\n",
    "    return dim_rate_code\n",
    "\n",
    "   \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "299479fb-8c6d-46c2-974d-418452b4e7f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dimension that needs to be downloaded \n",
    "\n",
    "import requests\n",
    "def load_taxi_zone_dimension():    \n",
    "    url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "    local_path = \"/tmp/taxi_zone_lookup.csv\"\n",
    "\n",
    "    print(f\"Downloading taxi zone lookup from {url}...\")\n",
    "    response = requests.get(url)\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Load to DBFS\n",
    "    dbfs_path = \"/FileStore/tables/taxi_zone_lookup.csv\"\n",
    "    dbutils.fs.cp(f\"file:{local_path}\", f\"dbfs:{dbfs_path}\")\n",
    "\n",
    "    # Read the CSV into a DataFrame\n",
    "    dim_taxi_zone = spark.read.option(\"header\", \"true\").csv(dbfs_path)\n",
    "\n",
    "    # Rename columns to match some naming convention \n",
    "    dim_taxi_zone = dim_taxi_zone.withColumnRenamed(\"LocationID\", \"location_id\") \\\n",
    "                        .withColumnRenamed(\"Borough\", \"borough\") \\\n",
    "                        .withColumnRenamed(\"Zone\", \"zone\") \\\n",
    "                        .withColumnRenamed(\"service_zone\", \"service_zone\")\n",
    "\n",
    "    print(f\"Loaded taxi zone dimension with {dim_taxi_zone.count()} rows\")\n",
    "    delta_location = \"dbfs:/FileStore/tables/dim_taxi_zone_delta\"\n",
    "    dim_taxi_zone.write.format(\"delta\").mode(\"overwrite\").save(delta_location)\n",
    "\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS nyc_db.dim_taxi_zone USING DELTA LOCATION '{delta_location}'\")\n",
    "    print(f\"Table nyc_db.dim_taxi_zone registered in metastore\")\n",
    "    print(\"Sample data:\")\n",
    "    dim_taxi_zone.show(5)\n",
    "\n",
    "    return dim_taxi_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c72930d8-881a-4984-b801-2502681da124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of data quality after all transformations so far \n",
    "\n",
    "def perform_data_quality_check(raw_df, clean_df, tables_dict):\n",
    "  \n",
    "    print(\"\\n---  DATA QUALITY ANALYSIS ---\\n\")\n",
    "    \n",
    "    # Calculate counts and percentages\n",
    "    initial_count = raw_df.count()\n",
    "    final_count = clean_df.count()\n",
    "    retention_pct = (final_count / initial_count) * 100\n",
    "    \n",
    "    print(f\"Initial row count: {initial_count}\")\n",
    "    print(f\"Final row count after cleaning: {final_count}\")\n",
    "    print(f\"Data retention: {retention_pct:.2f}%\")\n",
    "    # Generate warning if data quality issues exist\n",
    "    if retention_pct < 85:\n",
    "        print(\"\\nWARNING: Significant data loss during cleaning (retention < 85%). Further investigation needed.\")\n",
    "    \n",
    "\n",
    "    # Return a summary dictionary for reporting\n",
    "    return {\n",
    "        \"initial_count\": initial_count,\n",
    "        \"final_count\": final_count,\n",
    "        \"retention_pct\": retention_pct\n",
    "        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98532b68-ea24-4f77-ac82-47e4ebae32f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_zone_analytics_report():\n",
    "    \n",
    "    print(\"\\n--- ZONE ANALYTICS REPORT ---\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Query 1: Top pickup boroughs by trip count\n",
    "    print(\"Top pickup boroughs by trip count:\")\n",
    "    \n",
    "    pickup_borough_query = \"\"\"\n",
    "        SELECT\n",
    "            tz.borough as pickup_borough,\n",
    "            COUNT(*) as trip_count,\n",
    "            ROUND(AVG(f.total_amount), 2) as avg_fare,\n",
    "            ROUND(SUM(f.total_amount), 2) as total_revenue\n",
    "        FROM nyc_db.fact_trips f\n",
    "        LEFT JOIN nyc_db.dim_taxi_zone tz ON f.PULocationID = tz.location_id\n",
    "        WHERE tz.borough IS NOT NULL\n",
    "        GROUP BY tz.borough\n",
    "        ORDER BY trip_count DESC\n",
    "    \"\"\"\n",
    "    spark.sql(pickup_borough_query).show()\n",
    "    \n",
    "    # Query 2: Top routes (zone pairs) by revenue\n",
    "    print(\"Top 10 routes (zone pairs) by revenue:\")\n",
    "    \n",
    "    top_routes_query = \"\"\"\n",
    "        SELECT\n",
    "            pz.zone as pickup_zone,\n",
    "            dz.zone as dropoff_zone,\n",
    "            COUNT(*) as trip_count,\n",
    "            ROUND(AVG(f.trip_distance), 2) as avg_distance,\n",
    "            ROUND(AVG(f.trip_duration_minutes), 2) as avg_duration,\n",
    "            ROUND(SUM(f.total_amount), 2) as total_revenue\n",
    "        FROM nyc_db.fact_trips f\n",
    "        LEFT JOIN nyc_db.dim_taxi_zone pz ON f.PULocationID = pz.location_id\n",
    "        LEFT JOIN nyc_db.dim_taxi_zone dz ON f.DOLocationID = dz.location_id\n",
    "        WHERE pz.zone IS NOT NULL AND dz.zone IS NOT NULL\n",
    "        GROUP BY pz.zone, dz.zone\n",
    "        ORDER BY total_revenue DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    spark.sql(top_routes_query).show()\n",
    "    \n",
    "    # Query 3: Average trip metrics by payment type\n",
    "    print(\"Average trip metrics by payment type:\")\n",
    "    \n",
    "    payment_metrics_query = \"\"\"\n",
    "        SELECT\n",
    "            pt.payment_type_desc,\n",
    "            COUNT(*) as trip_count,\n",
    "            ROUND(AVG(f.trip_distance), 2) as avg_distance,\n",
    "            ROUND(AVG(f.fare_amount), 2) as avg_fare,\n",
    "            ROUND(AVG(f.tip_amount), 2) as avg_tip,\n",
    "            ROUND(AVG(f.tip_amount / CASE WHEN f.fare_amount > 0 THEN f.fare_amount ELSE NULL END) * 100, 2) as tip_percentage\n",
    "        FROM nyc_db.fact_trips f\n",
    "        LEFT JOIN nyc_db.dim_taxi_zone pz ON f.PULocationID = pz.location_id\n",
    "        LEFT JOIN nyc_db.dim_taxi_zone dz ON f.DOLocationID = dz.location_id\n",
    "        LEFT JOIN nyc_db.dim_payment_type pt ON f.payment_type = pt.payment_type\n",
    "        GROUP BY pt.payment_type_desc\n",
    "        ORDER BY trip_count DESC\n",
    "    \"\"\"\n",
    "    spark.sql(payment_metrics_query).show()\n",
    "    \n",
    "    # Query 4: Trip metrics by rate code\n",
    "    print(\"Trip metrics by rate code:\")\n",
    "    \n",
    "    rate_code_metrics_query = \"\"\"\n",
    "        SELECT\n",
    "            rc.rate_code_desc,\n",
    "            COUNT(*) as trip_count,\n",
    "            ROUND(AVG(f.trip_distance), 2) as avg_distance,\n",
    "            ROUND(AVG(f.trip_duration_minutes), 2) as avg_duration,\n",
    "            ROUND(AVG(f.price_per_mile), 2) as avg_price_per_mile,\n",
    "            ROUND(SUM(f.total_amount), 2) as total_revenue\n",
    "        FROM nyc_db.fact_trips f\n",
    "        LEFT JOIN nyc_db.dim_taxi_zone pz ON f.PULocationID = pz.location_id\n",
    "        LEFT JOIN nyc_db.dim_taxi_zone dz ON f.DOLocationID = dz.location_id\n",
    "        LEFT JOIN nyc_db.dim_rate_code rc ON f.RateCodeID = rc.RateCodeID\n",
    "        GROUP BY rc.rate_code_desc\n",
    "        ORDER BY trip_count DESC\n",
    "    \"\"\"\n",
    "    spark.sql(rate_code_metrics_query).show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb00bd43-baa6-4aea-ac66-9130019080f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_analytical_queries():\n",
    "    \n",
    "    print(\"\\n--- ANALYTICS RESULTS ---\\n\")\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    # Query 1: What are the busiest hours for taxi trips?\n",
    "    print(\"Query 1: Busiest hours for taxi trips\")\n",
    "    busiest_hours = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            pickup_hour,\n",
    "            COUNT(*) as trip_count\n",
    "        FROM nyc_db.fact_trips f\n",
    "        JOIN nyc_db.dim_time t ON f.tpep_pickup_datetime = t.tpep_pickup_datetime\n",
    "        GROUP BY pickup_hour\n",
    "        ORDER BY trip_count DESC\n",
    "    \"\"\")\n",
    "    busiest_hours.show(24)\n",
    "    results[\"busiest_hours\"] = busiest_hours\n",
    "    \n",
    "    # Query 2: Payment type analysis\n",
    "    print(\"Payment type distribution analysis:\")\n",
    "    payment_analysis = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            pt.payment_type,pt.payment_type_desc,\n",
    "            COUNT(*) as trip_count,\n",
    "            ROUND(AVG(f.fare_amount), 2) as avg_fare,\n",
    "            ROUND(AVG(f.tip_amount), 2) as avg_tip,\n",
    "            ROUND(SUM(f.total_amount), 2) as total_revenue\n",
    "        FROM nyc_db.fact_trips f\n",
    "        JOIN nyc_db.dim_payment_type pt ON f.payment_type = pt.payment_type\n",
    "        GROUP BY pt.payment_type,pt.payment_type_desc\n",
    "        ORDER BY trip_count DESC\n",
    "    \"\"\")\n",
    "    payment_analysis.show()\n",
    "    results[\"payment_analysis\"] = payment_analysis\n",
    "    \n",
    "    # Query 3: Rate code analysis\n",
    "    print(\"Rate code distribution analysis:\")\n",
    "    rate_code_analysis = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            rc.rate_code_desc,\n",
    "            COUNT(*) as trip_count,\n",
    "            ROUND(AVG(f.trip_distance), 2) as avg_distance,\n",
    "            ROUND(AVG(f.total_amount), 2) as avg_fare,\n",
    "            ROUND(SUM(f.total_amount), 2) as total_revenue\n",
    "        FROM nyc_db.fact_trips f\n",
    "        JOIN nyc_db.dim_rate_code rc ON f.RateCodeID = rc.RateCodeID\n",
    "        GROUP BY rc.rate_code_desc\n",
    "        ORDER BY trip_count DESC\n",
    "    \"\"\")\n",
    "    rate_code_analysis.show()\n",
    "    results[\"rate_code_analysis\"] = rate_code_analysis\n",
    "    \n",
    "    # Query 4: Cross-dimension analysis: Payment method by rate code\n",
    "    print(\"Payment method by rate code:\")\n",
    "    cross_analysis = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            rc.rate_code_desc,\n",
    "            pt.payment_type_desc,\n",
    "            COUNT(*) as count\n",
    "        FROM nyc_db.fact_trips f\n",
    "        JOIN nyc_db.dim_payment_type pt ON f.payment_type = pt.payment_type\n",
    "        JOIN nyc_db.dim_rate_code rc ON f.RateCodeID = rc.RateCodeID\n",
    "        GROUP BY rc.rate_code_desc, pt.payment_type_desc\n",
    "        ORDER BY rc.rate_code_desc, count DESC\n",
    "    \"\"\")\n",
    "    cross_analysis.show()\n",
    "    results[\"cross_analysis\"] = cross_analysis\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd21383b-864e-4be7-9153-54b7229592bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analyze_location_patterns():\n",
    "    \"\"\"\n",
    "    Analyze trip patterns using the location dimension\n",
    "    \"\"\"\n",
    "    print(\"\\n--- LOCATION PATTERN ANALYSIS ---\\n\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # Query 1: Most popular pickup locations\n",
    "    print(\"Top 10 most popular pickup locations:\")\n",
    "    popular_pickups = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            l.location_id,\n",
    "            COUNT(*) as pickup_count,borough,zone,service_zone,\n",
    "            AVG(f.trip_distance) as avg_distance,\n",
    "            AVG(f.fare_amount) as avg_fare,\n",
    "            SUM(f.total_amount) as total_revenue\n",
    "        FROM nyc_db.fact_trips f\n",
    "        JOIN nyc_db.dim_taxi_zone l ON f.PULocationID = l.location_id\n",
    "        GROUP BY l.location_id,borough,zone,service_zone\n",
    "        ORDER BY pickup_count DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    popular_pickups.show()\n",
    "    \n",
    "    # Query 2: Most popular dropoff locations\n",
    "    print(\"Top 10 most popular dropoff locations:\")\n",
    "    popular_dropoffs = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            l.location_id,borough,zone,service_zone,\n",
    "            COUNT(*) as dropoff_count,\n",
    "            AVG(f.trip_distance) as avg_distance,\n",
    "            AVG(f.fare_amount) as avg_fare,\n",
    "            SUM(f.total_amount) as total_revenue\n",
    "        FROM nyc_db.fact_trips f\n",
    "        JOIN nyc_db.dim_taxi_zone l ON f.DOLocationID = l.location_id\n",
    "        GROUP BY l.location_id,borough,zone,service_zone\n",
    "        ORDER BY dropoff_count DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    popular_dropoffs.show()\n",
    "    \n",
    "    # Query 3: Top location pairs (routes)\n",
    "    print(\"Top 10 most popular routes:\")\n",
    "    popular_routes = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            f.PULocationID as pickup_id,\n",
    "            f.DOLocationID as dropoff_id,\n",
    "            COUNT(*) as trip_count,\n",
    "            AVG(f.trip_distance) as avg_distance,\n",
    "            AVG(f.trip_duration_minutes) as avg_duration,\n",
    "            SUM(f.total_amount) as total_revenue\n",
    "        FROM nyc_db.fact_trips f\n",
    "        GROUP BY f.PULocationID, f.DOLocationID\n",
    "        ORDER BY trip_count DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    popular_routes.show()\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"popular_pickups\": popular_pickups,\n",
    "        \"popular_dropoffs\": popular_dropoffs,\n",
    "        \"popular_routes\": popular_routes\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16a7a00f-d042-48b6-8e4c-5d94ecdee391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_nyc_taxi_data(year, month):\n",
    "    \"\"\"\n",
    "    End to End pipeline calling\n",
    "    \"\"\"\n",
    "    print(\"Downloading uellow taxi data for Year {year} and Month {month}\")\n",
    "    raw_df= download_and_load_yellow_tripdata(year,month)\n",
    "\n",
    "    print(\"Checking and removing duplicates \")     \n",
    "    clean_df, raw_df_duplicates = process_duplicates(raw_df)\n",
    "    \n",
    "    print(\"Checking and removing nulls \")\n",
    "    clean_no_null_df=drop_null_rows(clean_df)\n",
    "\n",
    "    print(\"Converting negative amount to positive for currency columns\")\n",
    "    nonull_df_positive_amount = convert_negative_to_positive_amounts(clean_no_null_df)\n",
    "\n",
    "    print(\"enriching the data frame\")\n",
    "    enhanced_df= enhance_taxi_data(nonull_df_positive_amount)\n",
    "   \n",
    "    print(\"Creating the dimensional tables from the downloaded and enhanced data\")\n",
    "    tables = create_dimensional_model(enhanced_df)\n",
    "   \n",
    "    print(\"Saving tables to Delta\")\n",
    "    save_to_delta(tables)\n",
    "    \n",
    "    print(\"Creating the additinal dimensional tables from lookup data\")\n",
    "    dim_payment_type = create_payment_type_dimension()\n",
    "    dim_rate_code = create_rate_code_dimension()\n",
    "    dim_taxi_zone = load_taxi_zone_dimension()\n",
    "    \n",
    "    # Add these to the tables dictionary\n",
    "    tables[\"dim_payment_type\"] = dim_payment_type\n",
    "    tables[\"dim_rate_code\"] = dim_rate_code\n",
    "    tables[\"dim_taxi_zone\"] = dim_taxi_zone\n",
    "    \n",
    "    # Perform data quality checks\n",
    "    quality_report = perform_data_quality_check(raw_df, enhanced_df, tables)\n",
    "    print(\"General analytical reports \")\n",
    "    analysis_results = run_analytical_queries()\n",
    "    \n",
    "    # Print some reports     \n",
    "    print(\"Zone related nalytical reports \")\n",
    "    zone_analysis = create_zone_analytics_report()\n",
    "\n",
    "    #print some pickup loation related rports \n",
    "\n",
    "    location_analysis=analyze_location_patterns()\n",
    "    # Save tables to Delta format\n",
    "    save_to_delta(tables, base_path=\"/FileStore/tables/nyc_taxi\")\n",
    "\n",
    "    # Verify the tables at the end\n",
    "    verify_saved_tables()\n",
    "    \n",
    "    print(\"\\nData processing complete.\")\n",
    "    return {\n",
    "        \"tables\": tables,\n",
    "        \"quality_report\": quality_report,\n",
    "        \"zone_analysis\": zone_analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "323dde1e-3e58-4cc9-bd57-601b17998bbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def verify_saved_tables(limit=5):\n",
    "    \n",
    "    print(\"\\n--- VERIFYING SAVED TABLES ---\\n\")\n",
    "    \n",
    "    # List of tables to verify\n",
    "    tables_to_verify = [\n",
    "        \"dim_time\", \n",
    "        \"dim_taxi_zone\", \n",
    "        \"dim_payment_type\",\n",
    "        \"dim_rate_code\",\n",
    "        \"fact_trips\" \n",
    " \n",
    "    ]\n",
    "    \n",
    "    # Set the database context\n",
    "    spark.sql(\"USE nyc_db\")\n",
    "    \n",
    "    # Check each table\n",
    "    for table_name in tables_to_verify:\n",
    "        try:\n",
    "            print(f\"\\nSample data from {table_name}:\")\n",
    "            result = spark.sql(f\"SELECT * FROM {table_name} LIMIT {limit}\")\n",
    "            result.show(truncate=False)\n",
    "            row_count = spark.sql(f\"SELECT COUNT(*) AS row_count FROM {table_name}\").collect()[0][0]\n",
    "            print(f\"Total rows in {table_name}: {row_count:,}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing table {table_name}: {str(e)}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"\\nTable verification complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26d3571d-1945-4fc0-965a-e0e8e94e82f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading uellow taxi data for Year {year} and Month {month}\nFile /tmp/yellow_tripdata_2021-08.parquet already exists. Skipping download.\nFile copied to DBFS at /FileStore/tables/yellow_tripdata_2021-08.parquet\nFile verification in DBFS: Success\nData loaded successfully. Row count: 2788757\nroot\n |-- VendorID: long (nullable = true)\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- tpep_dropoff_datetime: timestamp (nullable = true)\n |-- passenger_count: double (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- RatecodeID: double (nullable = true)\n |-- store_and_fwd_flag: string (nullable = true)\n |-- PULocationID: long (nullable = true)\n |-- DOLocationID: long (nullable = true)\n |-- payment_type: long (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- extra: double (nullable = true)\n |-- mta_tax: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- tolls_amount: double (nullable = true)\n |-- improvement_surcharge: double (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- congestion_surcharge: double (nullable = true)\n |-- airport_fee: double (nullable = true)\n\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n|       2| 2021-08-01 00:04:06|  2021-08-01 00:26:07|            2.0|         3.52|       1.0|                 N|          43|          42|           1|       16.5|  0.5|    0.5|      5.08|         0.0|                  0.3|       25.38|                 2.5|        0.0|\n|       1| 2021-08-01 00:34:14|  2021-08-01 00:43:02|            0.0|          2.1|       1.0|                 N|          79|         233|           2|        9.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.8|                 2.5|        0.0|\n|       1| 2021-08-01 00:43:53|  2021-08-01 00:55:04|            0.0|          1.4|       1.0|                 N|         170|          90|           1|        8.5|  3.0|    0.5|      3.05|         0.0|                  0.3|       15.35|                 2.5|        0.0|\n|       1| 2021-08-01 00:53:19|  2021-08-01 00:55:34|            1.0|          0.4|       1.0|                 N|         229|         229|           1|        4.0|  3.0|    0.5|      1.17|         0.0|                  0.3|        8.97|                 2.5|        0.0|\n|       1| 2021-08-01 00:58:54|  2021-08-01 01:11:23|            1.0|          2.9|       1.0|                 N|         233|         249|           1|       12.0|  3.0|    0.5|       2.0|         0.0|                  0.3|        17.8|                 2.5|        0.0|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\nonly showing top 5 rows\n\nNumber of rows loaded to raw_df is: 2788757\nChecking and removing duplicates \nOriginal record count before deduplication: 2788757\nDistinct record count after dedupliation: 2788757\nNo duplicates found\nQUALITY REPORT: No duplicates found\nChecking and removing nulls \nOriginal row count: 2788757\nFinal row count: 2788757\nTotal rows removed: 0\nNull counts by column:\n  - trip_distance: 0 rows\n  - total_amount: 0 rows\nConverting negative amount to positive for currency columns\nNegative currency values found (before conversion):\n  - fare_amount: 12725\n  - tip_amount: 396\n  - tolls_amount: 366\n  - extra: 5600\n  - mta_tax: 12572\n  - improvement_surcharge: 12857\n  - congestion_surcharge: 10103\n  - Airport_fee: 1074\n  - total_amount: 12903\n\nTotal rows processed: 2788757\nAll specified currency amounts converted to positive values.\nenriching the data frame\nData enhancement complete:\n- Original columns: 19\n- Enhanced columns: 24\n- New columns added: 5\n- Row count: 2788757 (unchanged from original: 2788757)\nCreating the dimensional tables from the downloaded and enhanced data\nCreating dimensional model...\nTime dimension count: 1539011\nFact table count: 2788757\nroot\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- pickup_hour: integer (nullable = true)\n |-- pickup_date: date (nullable = true)\n |-- pickup_day_of_week: string (nullable = true)\n\nroot\n |-- trip_id: long (nullable = false)\n |-- VendorID: long (nullable = true)\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- tpep_dropoff_datetime: timestamp (nullable = true)\n |-- PULocationID: long (nullable = true)\n |-- DOLocationID: long (nullable = true)\n |-- passenger_count: double (nullable = true)\n |-- payment_type: long (nullable = true)\n |-- RateCodeID: double (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- trip_duration_minutes: double (nullable = true)\n |-- price_per_mile: double (nullable = true)\n\nSaving tables to Delta\nSaving tables to Delta format at /FileStore/tables/nyc_taxi...\nDatabase nyc_db created or already exists\nSaving table dim_time to /FileStore/tables/nyc_taxi/dim_time\nroot\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- pickup_hour: integer (nullable = true)\n |-- pickup_date: date (nullable = true)\n |-- pickup_day_of_week: string (nullable = true)\n\nSaved dim_time to Delta format\nTable nyc_db.dim_time registered in metastore\nSaving table fact_trips to /FileStore/tables/nyc_taxi/fact_trips\nroot\n |-- trip_id: long (nullable = false)\n |-- VendorID: long (nullable = true)\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- tpep_dropoff_datetime: timestamp (nullable = true)\n |-- PULocationID: long (nullable = true)\n |-- DOLocationID: long (nullable = true)\n |-- passenger_count: double (nullable = true)\n |-- payment_type: long (nullable = true)\n |-- RateCodeID: double (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- trip_duration_minutes: double (nullable = true)\n |-- price_per_mile: double (nullable = true)\n\nSaved fact_trips to Delta format\nTable nyc_db.fact_trips registered in metastore\nAll tables saved to Delta format successfully\nCreating the additinal dimensional tables from lookup data\nTable nyc_db.dim_payment_type registered in metastore\nSample data:\n+------------+-----------------+\n|payment_type|payment_type_desc|\n+------------+-----------------+\n|           1|      Credit card|\n|           2|             Cash|\n|           3|        No charge|\n|           4|          Dispute|\n|           5|          Unknown|\n+------------+-----------------+\nonly showing top 5 rows\n\nTable nyc_db.dim_rate_code registered in metastore\nSample data:\n+----------+--------------------+\n|RateCodeID|      rate_code_desc|\n+----------+--------------------+\n|         1|       Standard rate|\n|         2|                 JFK|\n|         3|              Newark|\n|         4|Nassau or Westche...|\n|         5|     Negotiated fare|\n+----------+--------------------+\nonly showing top 5 rows\n\nDownloading taxi zone lookup from https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv...\nLoaded taxi zone dimension with 265 rows\nTable nyc_db.dim_taxi_zone registered in metastore\nSample data:\n+-----------+-------------+--------------------+------------+\n|location_id|      borough|                zone|service_zone|\n+-----------+-------------+--------------------+------------+\n|          1|          EWR|      Newark Airport|         EWR|\n|          2|       Queens|         Jamaica Bay|   Boro Zone|\n|          3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n|          4|    Manhattan|       Alphabet City| Yellow Zone|\n|          5|Staten Island|       Arden Heights|   Boro Zone|\n+-----------+-------------+--------------------+------------+\nonly showing top 5 rows\n\n\n---  DATA QUALITY ANALYSIS ---\n\nInitial row count: 2788757\nFinal row count after cleaning: 2788757\nData retention: 100.00%\nGeneral analytical reports \n\n--- ANALYTICS RESULTS ---\n\nQuery 1: Busiest hours for taxi trips\n+-----------+----------+\n|pickup_hour|trip_count|\n+-----------+----------+\n|         18|    202403|\n|         17|    195086|\n|         15|    183926|\n|         16|    180982|\n|         19|    180799|\n|         14|    180254|\n|         13|    168014|\n|         12|    163384|\n|         20|    150213|\n|         11|    145463|\n|         21|    134152|\n|         10|    133968|\n|         22|    121223|\n|          9|    119517|\n|          8|    103964|\n|         23|     96804|\n|          7|     74401|\n|          0|     72740|\n|          1|     48401|\n|          6|     44151|\n|          2|     32965|\n|          3|     22277|\n|          5|     17760|\n|          4|     15910|\n+-----------+----------+\n\nPayment type distribution analysis:\n+------------+-----------------+----------+--------+-------+-------------+\n|payment_type|payment_type_desc|trip_count|avg_fare|avg_tip|total_revenue|\n+------------+-----------------+----------+--------+-------+-------------+\n|           1|      Credit card|   2005222|   13.45|   3.14| 4.12952612E7|\n|           2|             Cash|    623420|   13.23|    0.0|1.056652346E7|\n|           3|        No charge|     13317|    11.6|   0.03|    199205.83|\n|           4|          Dispute|     11208|   13.61|    0.1|    193844.37|\n+------------+-----------------+----------+--------+-------+-------------+\n\nRate code distribution analysis:\n+--------------------+----------+------------+--------+-------------+\n|      rate_code_desc|trip_count|avg_distance|avg_fare|total_revenue|\n+--------------------+----------+------------+--------+-------------+\n|       Standard rate|   2551884|        2.82|   17.64|4.500659194E7|\n|                 JFK|     76484|       17.38|   70.09|   5360635.48|\n|     Negotiated fare|     14990|        5.83|   69.65|   1044058.51|\n|              Newark|      5428|       16.49|   89.31|    484779.25|\n|Nassau or Westche...|      4173|       20.95|   84.61|    353076.09|\n|             Unknown|       192|        0.71|    22.1|      4242.24|\n|          Group ride|        16|        1.86|   90.71|      1451.35|\n+--------------------+----------+------------+--------+-------------+\n\nPayment method by rate code:\n+--------------------+-----------------+-----+\n|      rate_code_desc|payment_type_desc|count|\n+--------------------+-----------------+-----+\n|          Group ride|        No charge|    6|\n|          Group ride|      Credit card|    4|\n|          Group ride|             Cash|    4|\n|          Group ride|          Dispute|    2|\n|                 JFK|      Credit card|60011|\n|                 JFK|             Cash|15494|\n|                 JFK|          Dispute|  490|\n|                 JFK|        No charge|  489|\n|Nassau or Westche...|      Credit card| 2577|\n|Nassau or Westche...|             Cash| 1506|\n|Nassau or Westche...|        No charge|   55|\n|Nassau or Westche...|          Dispute|   35|\n|     Negotiated fare|      Credit card|12232|\n|     Negotiated fare|             Cash| 2033|\n|     Negotiated fare|        No charge|  457|\n|     Negotiated fare|          Dispute|  268|\n|              Newark|      Credit card| 3957|\n|              Newark|             Cash| 1251|\n|              Newark|        No charge|  129|\n|              Newark|          Dispute|   91|\n+--------------------+-----------------+-----+\nonly showing top 20 rows\n\nZone related nalytical reports \n\n--- ZONE ANALYTICS REPORT ---\n\nTop pickup boroughs by trip count:\n+--------------+----------+--------+-------------+\n|pickup_borough|trip_count|avg_fare|total_revenue|\n+--------------+----------+--------+-------------+\n|     Manhattan|   2488499|   17.23|4.288300191E7|\n|        Queens|    227168|   49.39|1.122070018E7|\n|      Brooklyn|     30836|   31.67|    976575.91|\n|       Unknown|     19631|   27.91|    547972.49|\n|           N/A|     12963|   54.82|    710692.86|\n|         Bronx|      9052|   38.07|    344600.23|\n| Staten Island|       319|   89.99|     28707.61|\n|           EWR|       289|   92.35|     26688.54|\n+--------------+----------+--------+-------------+\n\nTop 10 routes (zone pairs) by revenue:\n+--------------------+--------------------+----------+------------+------------+-------------+\n|         pickup_zone|        dropoff_zone|trip_count|avg_distance|avg_duration|total_revenue|\n+--------------------+--------------------+----------+------------+------------+-------------+\n|         JFK Airport|      Outside of NYC|      4897|       21.85|       44.06|    449741.21|\n|         JFK Airport|Times Sq/Theatre ...|      2819|       18.33|       51.46|    199753.76|\n|                 N/A|                 N/A|      9023|        2.59|       15.98|    197179.84|\n|         JFK Airport|        Clinton East|      2522|       18.48|       48.93|    177935.84|\n|Upper East Side S...|Upper East Side N...|     14613|        1.09|        7.55|    167904.86|\n|Upper East Side N...|Upper East Side S...|     12684|        1.08|        8.33|    149298.96|\n|      Outside of NYC|      Outside of NYC|      1395|        2.33|        3.42|    138926.75|\n|         JFK Airport|         Murray Hill|      1805|       17.15|       40.86|    130628.89|\n|   LaGuardia Airport|Times Sq/Theatre ...|      2622|       10.53|       34.88|    130523.95|\n|   LaGuardia Airport|      Outside of NYC|      1295|       23.13|       52.56|    129826.46|\n+--------------------+--------------------+----------+------------+------------+-------------+\n\nAverage trip metrics by payment type:\n+-----------------+----------+------------+--------+-------+--------------+\n|payment_type_desc|trip_count|avg_distance|avg_fare|avg_tip|tip_percentage|\n+-----------------+----------+------------+--------+-------+--------------+\n|      Credit card|   2005222|        3.33|   13.45|   3.14|         28.23|\n|             Cash|    623420|        3.28|   13.23|    0.0|           0.0|\n|             null|    135590|        92.9|   26.22|   2.64|         13.67|\n|        No charge|     13317|        2.33|    11.6|   0.03|          0.67|\n|          Dispute|     11208|        2.83|   13.61|    0.1|           0.7|\n+-----------------+----------+------------+--------+-------+--------------+\n\nTrip metrics by rate code:\n+--------------------+----------+------------+------------+------------------+-------------+\n|      rate_code_desc|trip_count|avg_distance|avg_duration|avg_price_per_mile|total_revenue|\n+--------------------+----------+------------+------------+------------------+-------------+\n|       Standard rate|   2551884|        2.82|       15.25|              5.53|4.500659194E7|\n|                null|    135590|        92.9|       22.91|              8.25|   4484104.87|\n|                 JFK|     76484|       17.38|       46.52|             50.93|   5360635.48|\n|     Negotiated fare|     14990|        5.83|       15.57|            154.86|   1044058.51|\n|              Newark|      5428|       16.49|       43.97|             29.52|    484779.25|\n|Nassau or Westche...|      4173|       20.95|       41.15|              3.59|    353076.09|\n|             Unknown|       192|        0.71|        13.3|               2.8|      4242.24|\n|          Group ride|        16|        1.86|        0.69|              3.01|      1451.35|\n+--------------------+----------+------------+------------+------------------+-------------+\n\n\n--- LOCATION PATTERN ANALYSIS ---\n\nTop 10 most popular pickup locations:\n+-----------+------------+---------+--------------------+------------+------------------+------------------+------------------+\n|location_id|pickup_count|  borough|                zone|service_zone|      avg_distance|          avg_fare|     total_revenue|\n+-----------+------------+---------+--------------------+------------+------------------+------------------+------------------+\n|        132|      122820|   Queens|         JFK Airport|    Airports|15.504930141671037| 45.22570688812891| 7092365.329991836|\n|        237|      122484|Manhattan|Upper East Side S...| Yellow Zone| 1.939472747460889| 9.464941461741743|1841034.8600016513|\n|        236|      103324|Manhattan|Upper East Side N...| Yellow Zone|3.7696347412024025| 10.10739315163924|1632357.9000012614|\n|        186|      101790|Manhattan|Penn Station/Madi...| Yellow Zone|2.5252023774437857|11.575010610079396|1777391.5100014168|\n|        161|       98048|Manhattan|      Midtown Center| Yellow Zone| 2.657767318048341|10.597329879242597| 1615645.530001257|\n|        170|       92757|Manhattan|         Murray Hill| Yellow Zone| 4.080997013702488| 10.87540951087198| 1564395.890001081|\n|        162|       88510|Manhattan|        Midtown East| Yellow Zone| 2.344710541181739|10.647700598802166|1470166.4600009813|\n|        142|       81752|Manhattan| Lincoln Square East| Yellow Zone|2.6197518103532405|10.514663861434206|1334392.8000008136|\n|         48|       81272|Manhattan|        Clinton East| Yellow Zone| 4.111700954818401|11.606714612658223|1421753.4200009555|\n|         79|       80185|Manhattan|        East Village| Yellow Zone| 4.109879154455336|11.833613768160355|1441099.7600008103|\n+-----------+------------+---------+--------------------+------------+------------------+------------------+------------------+\n\nTop 10 most popular dropoff locations:\n+-----------+---------+--------------------+------------+-------------+------------------+------------------+------------------+\n|location_id|  borough|                zone|service_zone|dropoff_count|      avg_distance|          avg_fare|     total_revenue|\n+-----------+---------+--------------------+------------+-------------+------------------+------------------+------------------+\n|        237|Manhattan|Upper East Side S...| Yellow Zone|       107078| 2.800221707540311|  9.03255738807194|  1562110.91000127|\n|        236|Manhattan|Upper East Side N...| Yellow Zone|       104992|3.2843561414202913| 9.805110008381313|1637514.0300012385|\n|        161|Manhattan|      Midtown Center| Yellow Zone|        89487| 3.259135852134968| 9.718300535272858| 1371597.900000966|\n|        170|Manhattan|         Murray Hill| Yellow Zone|        86808|  2.19248905630817|10.255475532208393| 1407892.000000908|\n|        141|Manhattan|     Lenox Hill West| Yellow Zone|        77860| 7.613093115848989| 10.02543475468748|1240672.1100007147|\n|         48|Manhattan|        Clinton East| Yellow Zone|        73585| 4.075079839641232|11.792051505061586|1325074.8900007962|\n|        239|Manhattan|Upper West Side S...| Yellow Zone|        73108|7.1938541609672875|10.919684849810702| 1255409.510000625|\n|        162|Manhattan|        Midtown East| Yellow Zone|        72206| 4.964890452316995|10.196276348225485|1164545.9600005976|\n|        142|Manhattan| Lincoln Square East| Yellow Zone|        70754|3.3722289905870984|10.181669587584755|1140180.0500005535|\n|        186|Manhattan|Penn Station/Madi...| Yellow Zone|        67852| 5.574734864116042|10.604221688380129| 1116302.580000573|\n+-----------+---------+--------------------+------------+-------------+------------------+------------------+------------------+\n\nTop 10 most popular routes:\n+---------+----------+----------+------------------+------------------+------------------+\n|pickup_id|dropoff_id|trip_count|      avg_distance|      avg_duration|     total_revenue|\n+---------+----------+----------+------------------+------------------+------------------+\n|      237|       236|     14613|1.0942250051324176| 7.549437487168948|167904.85999999673|\n|      236|       237|     12684|1.0832253232418851| 8.326538946704494| 149298.9600000033|\n|      237|       237|     11277|0.6771667996807671| 6.714036534539335|120705.74000001134|\n|      236|       236|      9445|0.6549835892006354| 5.352537850714648|  97371.3900000079|\n|      264|       264|      9023|2.5945849495733135|15.976606450183022|197179.83999999036|\n|      237|       161|      7040| 1.143517045454547| 8.811136363636367| 84529.74000000466|\n|      161|       237|      6706|1.1151327169698793| 9.056118401431553| 80021.32000000456|\n|      239|       142|      6325|0.9068901185770735| 7.576743083003934| 68605.50000000311|\n|      239|       238|      6235|0.8497145148356038| 6.001212510024044| 65772.30000000303|\n|      142|       239|      6184|1.0092205692108693| 7.025237710219921| 69558.30000000329|\n+---------+----------+----------+------------------+------------------+------------------+\n\nSaving tables to Delta format at /FileStore/tables/nyc_taxi...\nDatabase nyc_db created or already exists\nSaving table dim_time to /FileStore/tables/nyc_taxi/dim_time\nroot\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- pickup_hour: integer (nullable = true)\n |-- pickup_date: date (nullable = true)\n |-- pickup_day_of_week: string (nullable = true)\n\nSaved dim_time to Delta format\nTable nyc_db.dim_time registered in metastore\nSaving table fact_trips to /FileStore/tables/nyc_taxi/fact_trips\nroot\n |-- trip_id: long (nullable = false)\n |-- VendorID: long (nullable = true)\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- tpep_dropoff_datetime: timestamp (nullable = true)\n |-- PULocationID: long (nullable = true)\n |-- DOLocationID: long (nullable = true)\n |-- passenger_count: double (nullable = true)\n |-- payment_type: long (nullable = true)\n |-- RateCodeID: double (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- trip_duration_minutes: double (nullable = true)\n |-- price_per_mile: double (nullable = true)\n\nSaved fact_trips to Delta format\nTable nyc_db.fact_trips registered in metastore\nSaving table dim_payment_type to /FileStore/tables/nyc_taxi/dim_payment_type\nroot\n |-- payment_type: integer (nullable = false)\n |-- payment_type_desc: string (nullable = false)\n\nSaved dim_payment_type to Delta format\nTable nyc_db.dim_payment_type registered in metastore\nSaving table dim_rate_code to /FileStore/tables/nyc_taxi/dim_rate_code\nroot\n |-- RateCodeID: integer (nullable = false)\n |-- rate_code_desc: string (nullable = false)\n\nSaved dim_rate_code to Delta format\nTable nyc_db.dim_rate_code registered in metastore\nSaving table dim_taxi_zone to /FileStore/tables/nyc_taxi/dim_taxi_zone\nroot\n |-- location_id: string (nullable = true)\n |-- borough: string (nullable = true)\n |-- zone: string (nullable = true)\n |-- service_zone: string (nullable = true)\n\nSaved dim_taxi_zone to Delta format\nTable nyc_db.dim_taxi_zone registered in metastore\nAll tables saved to Delta format successfully\n\n--- VERIFYING SAVED TABLES ---\n\n\nSample data from dim_time:\n+--------------------+-----------+-----------+------------------+\n|tpep_pickup_datetime|pickup_hour|pickup_date|pickup_day_of_week|\n+--------------------+-----------+-----------+------------------+\n|2021-08-01 00:44:09 |0          |2021-08-01 |Sunday            |\n|2021-08-01 00:01:51 |0          |2021-08-01 |Sunday            |\n|2021-08-01 00:11:35 |0          |2021-08-01 |Sunday            |\n|2021-08-01 00:45:42 |0          |2021-08-01 |Sunday            |\n|2021-08-01 00:48:08 |0          |2021-08-01 |Sunday            |\n+--------------------+-----------+-----------+------------------+\n\nTotal rows in dim_time: 1,539,011\n\nSample data from dim_taxi_zone:\n+-----------+-------------+-----------------------+------------+\n|location_id|borough      |zone                   |service_zone|\n+-----------+-------------+-----------------------+------------+\n|1          |EWR          |Newark Airport         |EWR         |\n|2          |Queens       |Jamaica Bay            |Boro Zone   |\n|3          |Bronx        |Allerton/Pelham Gardens|Boro Zone   |\n|4          |Manhattan    |Alphabet City          |Yellow Zone |\n|5          |Staten Island|Arden Heights          |Boro Zone   |\n+-----------+-------------+-----------------------+------------+\n\nTotal rows in dim_taxi_zone: 265\n\nSample data from dim_payment_type:\n+------------+-----------------+\n|payment_type|payment_type_desc|\n+------------+-----------------+\n|1           |Credit card      |\n|2           |Cash             |\n|3           |No charge        |\n|4           |Dispute          |\n|5           |Unknown          |\n+------------+-----------------+\n\nTotal rows in dim_payment_type: 6\n\nSample data from dim_rate_code:\n+----------+---------------------+\n|RateCodeID|rate_code_desc       |\n+----------+---------------------+\n|1         |Standard rate        |\n|2         |JFK                  |\n|3         |Newark               |\n|4         |Nassau or Westchester|\n|5         |Negotiated fare      |\n+----------+---------------------+\n\nTotal rows in dim_rate_code: 7\n\nSample data from fact_trips:\n+-------+--------+--------------------+---------------------+------------+------------+---------------+------------+----------+-------------+-----------+----------+------------+---------------------+--------------+\n|trip_id|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|PULocationID|DOLocationID|passenger_count|payment_type|RateCodeID|trip_distance|fare_amount|tip_amount|total_amount|trip_duration_minutes|price_per_mile|\n+-------+--------+--------------------+---------------------+------------+------------+---------------+------------+----------+-------------+-----------+----------+------------+---------------------+--------------+\n|0      |2       |2021-08-01 00:04:06 |2021-08-01 00:26:07  |43          |42          |2.0            |1           |1.0       |3.52         |16.5       |5.08      |25.38       |22.02                |4.69          |\n|1      |1       |2021-08-01 00:34:14 |2021-08-01 00:43:02  |79          |233         |0.0            |2           |1.0       |2.1          |9.0        |0.0       |12.8        |8.8                  |4.29          |\n|2      |1       |2021-08-01 00:43:53 |2021-08-01 00:55:04  |170         |90          |0.0            |1           |1.0       |1.4          |8.5        |3.05      |15.35       |11.18                |6.07          |\n|3      |1       |2021-08-01 00:53:19 |2021-08-01 00:55:34  |229         |229         |1.0            |1           |1.0       |0.4          |4.0        |1.17      |8.97        |2.25                 |10.0          |\n|4      |1       |2021-08-01 00:58:54 |2021-08-01 01:11:23  |233         |249         |1.0            |1           |1.0       |2.9          |12.0       |2.0       |17.8        |12.48                |4.14          |\n+-------+--------+--------------------+---------------------+------------+------------+---------------+------------+----------+-------------+-----------+----------+------------+---------------------+--------------+\n\nTotal rows in fact_trips: 2,788,757\n\nTable verification complete.\n\nData processing complete.\nOut[142]: {'tables': {'dim_time': DataFrame[tpep_pickup_datetime: timestamp, pickup_hour: int, pickup_date: date, pickup_day_of_week: string],\n  'fact_trips': DataFrame[trip_id: bigint, VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, PULocationID: bigint, DOLocationID: bigint, passenger_count: double, payment_type: bigint, RateCodeID: double, trip_distance: double, fare_amount: double, tip_amount: double, total_amount: double, trip_duration_minutes: double, price_per_mile: double],\n  'dim_payment_type': DataFrame[payment_type: int, payment_type_desc: string],\n  'dim_rate_code': DataFrame[RateCodeID: int, rate_code_desc: string],\n  'dim_taxi_zone': DataFrame[location_id: string, borough: string, zone: string, service_zone: string]},\n 'quality_report': {'initial_count': 2788757,\n  'final_count': 2788757,\n  'retention_pct': 100.0},\n 'zone_analysis': None}"
     ]
    }
   ],
   "source": [
    "# call main function parameter year YYYY , Month M or MM\n",
    "# Example process_nyc_taxi_data(2024,1)\n",
    "# Example process_nyc_taxi_data(2024,12)\n",
    "process_nyc_taxi_data(2021,8)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3039968540422504,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "nyc_taxi_model_final",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
